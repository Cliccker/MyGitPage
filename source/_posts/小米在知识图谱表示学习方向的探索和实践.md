---
title: 小米在知识图谱表示学习方向的探索和实践
author: 吕荣荣
tags:
  - 知识图谱
  - 表示学习
date: 2021-06-30 21:14:32
categories: 学习
summary: 我给公众号DataFunTalk整理的一期报告
---

# 小米在知识图谱表示学习方向的探索和实践

这篇文章是我给公众号DataFunTalk整理的关于一次报告，初衷还是因为涉猎过一些知识图谱相关的知识，大家一起看看吧~



## 导读

今天为大家带来的分享内容是小米在知识图谱表示学习方向的探索和实践。主要围绕以下四点展开:

1. 业务介绍 小米知识图谱的架构和业务；
2. 算法介绍 融合文本和知识图谱的表示学习方法；
3. 算法应用 知识表示学习在实体链接、实体推荐、知识补全的应用；
4. 总结 总结和展望；

## 业务介绍

### 小米知识图谱团队

<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210614205319.png" alt="image-20210614205308023"  />

小米知识图谱团队，旨在硏究知识图谱在开放领域和行业领域的构建和应用技术，把知识图谱推广到相关的业务场景上。目前团队已经构建了超百亿目前团队已经构建了超百亿的开放知识，以及涉及十多个领域的高质量知识，提供了实体检索、实体链接、概念图谱等高质量的服务，并且服务于小爱同学、小米网、小米信息流等应用方的智能问答、智能客服商品推荐、商品搜索等业务。

### 知识图谱为小爱赋能

<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210614205503.png" alt="image-20210614205502641"  />

这是一个知识图谱为小爱赋能的例子。当用户询问巩俐的籍贯的时候，我们会从库中去给出相应的答案，并且会给出巩俐其他的一些实体信息。那么具体是怎么实现的呢？下面简单介绍一下处理流程。

<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210614205645.png" alt="image-20210614205644204"  />



当用户询问一个问题（query）时，语音设备首先会进行语音的识别，然后是意图的识别，比如说问题是“武汉大学周边有什么好吃的？”，它的解答流程就是：

1. 首先通过分析发现用户的意图是想询问”美食“相关的事物；

2. 然后通过实体匹配去进行实体的识别，实体的链接以及属性的归一等处理。确定用户询问的是“武汉大学”这个实体相关的推荐实体属性；

3. 据此从库中查询相应的结果，并且作为输出；

4. 另外我们还会针对该实体做实体的推荐，以此实现相似问题的推荐；

## 算法介绍

<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210614221139.png"  />

知识表示学习是指基于分布式的表示思想，将实体或者是关系的语义信息映射到低维、稠密、实值的向量空间中，使得语义相似的两个对象之间的距离也很相近。

常见的表示学习方法是融合事实信息的方法，比如基于翻译、张量分解、神经网络和图神经网络的各种模型，但是在这些大规模知识图谱中存在实体与关系长尾分布的问题，即极少数的个体占极高的数量，而大多数的个体只占了极少的数量。在图谱中，长尾分布体现为很多实体数量极少甚至没有关系事实，这就导致数据存在很严重的稀疏性。

对于这些长尾的实体和关系，在没有或者很少关系的情况下，仅基于传统的事实三元组（头部，关系，尾部）进行学习，是没有办法得到的。对此有什么解决办法？

1. 利用知识库中其他的信息，比如说文本描述信息、信息实体类型、关键路径、逻辑规则等，还包括实体的属性、时序信息、图结构等；
2. 利用知识库外的海量信息，比如说互联网等，包含大量知识库实体和关系的有关的信息；
3. 知识表示学习的应用，比如说知识图谱内的链接预测，三元组块分类、实体分类等，应用到知识图谱以外的，比如实体链接、实体推荐、关系抽取等；

### 融合文本描述的优势



<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615102729.png" alt="image-20210615102721468"  />

融合文本描述的优势有哪些？

+ 发掘实体之间的语义相关性，精确的语义表述能够提升三元组的可区分性。在上面的例子中我们可以看到{撒贝宁，配偶，李白}，而李白的描述文本中就存在”撒贝宁妻子“这样的关键词。该情境下，融合文本描述的语义信息能够帮助发掘更多的语义之间的相关性；

+ 当一些实体对于现有的知识图谱来说是新的，并且仅仅带有描述性信息的时候，传统的知识图谱表示学习方法不能够表示这些新的实体，因为图谱在训练的时候并没有考虑到这个概念，但是融入了文本描述的模型，就能够通过描述信息建立这些实体的表达；

通常将实体的类型、文本描述和重要的三元组按照一定的规则进行拼接，构成一段文本，作为实体的描述文本，这段文本比简单的文本描述包含更多的信息。

### 文本与知识图谱对齐

下面将会介绍两种经典的融合文本和知识图谱的知识表示学习方法，这两种方法都可以将实体向量、关系向量和词向量放到同一个语义空间下。为什么要把文本以及词向量放到一个空间中？因为如果我们遇到了需要同时处理文本和实体的任务，实体和文本中的单词做内积等向量运算才会有意义，依靠这些运算方法我们才能比较实体和文本之间的单词的关系。

<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615103857.png" alt="image-20210615103855754"  />

这一篇文章描述了比较经典的文本与知识图谱对齐的模型Jointly（联合模型），作者先后发表了两篇论文来优化该方法。

文章研究的内容是融合文本信息到知识图谱中，实现知识图谱中的实体和实体描述文本联合嵌入表示。

对齐模型的关键在于将实体向量、关系向量和词向量表示在同一个语义空间下。我们要求实体的表示向量不仅满足知识图谱的结构化约束，同时也要被文本描述中的词向量进行约束。

模型一共分为三个部分：

1. 文本嵌入，采用skip-gram模型，采用欧式距离衡量两个单词之间的相似性，训练词与词之间的约束；
2. 知识嵌入，采用是Trans-E模型，训练实体与实体之间的约束；
3. 对齐，利用文本描述对齐，训练实体和文本之间的约束，确保关系能够和文本的单词在同一个语义空间中。

<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615105048.png" alt="image-20210615105044367"  />

第二篇论文也根据类似的原理，将基于平移的嵌入方法从特定的三元组嵌入扩展到了文本感知模型，提出了名为DKRL的模型。该模型的特点是：

+ 对于事实元组论文采用了典型的Trans-E模型，通过最大似然值获得实体和关系的嵌入；

+ 对于描述文本，论文使用了连续词袋模型和深度卷积模型对文本进行嵌入。连续词袋模型忽略了文本的词序，而卷积模型会考虑词序；

对每一个实体，DKRL都会学习语义的嵌入和结构的嵌入，再通过右侧的一系列公式进行拟合。

### 需求和实现

<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615130621.png" alt="image-20210615130619966"  />

后续任务需要通过预训练得到词向量，实体向量，并且保证两者之间需要能够计算相似度，同时也要保证实体向量和实体向量之间可以计算相似度。上文介绍的两个模型均可以满足该需求。右上的表格展示了几个不同的模型在链接预测任务上的效果，联合模型，即第一篇论文中的模型展现了较好的效果，于是我们基于该模型对实体和词进行了训练，得到了词向量、关系向量以及实体向量。该模型的效果具体体现在：

+ 由图一（左上） 可以看到”王者荣耀“这个词和”李白“这个候选实体之间的相似度评分，该分数表明模型学习到了词和实体之间的关联；
+ 由图二（右上） 可以看到虽然”唐代诗人李白“的文本描述中不存在”将进酒“一词，但是模型也学到了其关联；

+ 图三图四（左下和右下）显示，模型也学习到了实体向量与实体向量之间的关系，比如植物”小米“实体向量和水果”苹果“实体向量比较靠近，而”小米公司“的实体向量和”苹果公司“的实体向量比较靠近；

这些特性对完成后续的任务有很大的帮助。

## 算法应用

### 实体链接

<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615132930.png" alt="image-20210615132928212"  />


实体链接把文本中的实体指称项，即实体名称，链接到知识库中对应的实体上。

举一个例子来帮助大家理解实体链接，比如问题”王者荣耀中的李白有哪些台词？“，为了解答这个问题我们需要：

1. 识别句子中的核心实体”李白“；
2. 从库中检索”李白“所有的候选实体；
3. 实体链接，从众多的是候选实体中找到正确的实体，与句子中的”李白“进行匹配；

实体链接的难点主要有两个方面：

+ 实体会有不同的表达方式（mention），比如”青年居士李太白“，也对应了李白这个实体。
+ 同一个表达方式也会对应不同的实体，比如说”王者荣耀中李白的技能是什么？“，”李白和杜甫并称为什么？“，这两句中实体的表达方式都是“李白”，但是对应了不同的实体。

<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615133844.png" alt="image-20210615133843183"  />

左侧图中展示了实体链接的处理流程，这里详细介绍一下实体消歧部分。

实体消歧包括两个模块，第一个部分是粗排，第二个部分是精排。

#### 关于粗排

**为什么要做粗排处理？**

在做候选实体生成时，我们希望从库中获取尽可能多的相关实体，确保没有遗漏正确实体。但这样做会导致消歧这一步骤被引入了太多的噪声，造成消歧效率的下降。所以需要粗排模型来降低候选实体的个数。经过实验，粗排后，消歧准确率提升了3%，预测的速度提升了50%，而召回率仅仅下降了0.4%。

举个例子，比如“王者荣耀中的李白有哪些台词？“这个问题，在我们的库中”王者荣耀“的候选实体有71个，”李白“的候选实体有59个。在粗排时，我们会为每一个候选实体进行打分，按照相关度从大到小进行排列，选择每一个mention所对应的最相似的n个实体(Top n)，作为精排的输入。

**如何实现粗排？**

<img src="https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615135927.png" alt="image-20210615135926159"  />

粗排模型，要求高精度、高性能。我们采用了上一节中融合多元信息知识表示学习方法所训练得到的实体向量和词向量，因为他们处在同一个向量空间中，我们可以对其进行向量计算。定义了三个特征，分别是Context和Coherence以及LinkCount：

+ Context 表示mention的上下文特征，它通过候选实体向量和问题中的每一个词向量进行乘积运算得到，用于发现问题中哪些词和候选实体相关。获取该特征的流程为：首先利用head attention选择Top R个词向量，通过softmax函数求这些词向量的相似度分数权重，所得的权重与其对应的词向量进行加权，作为问题的上下文向量表示，该向量与候选实体向量进行相乘，得到上下文特征；

+ Coherence 表示实体的一致性，通过计算候选实体和问题中不同mention的候选实体相关性来实现。每一个mention的候选实体仅保留一个，求取平均值作为Coherence的特征；
+ LinkCount 表示实体的先验知识，通过标注数据而来。计算的方法是mention链接到该实体的次数除以mention出现的次数；

利用一个多层感知机对这三个特征进行融合，最终得到每一个候选实体的粗排分数。

#### **关于精排**

![image-20210615142804860](https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615142806.png)

在粗排之后，每一个mention的候选实体个数被大大降低，此时我们会对这些实体进行精排处理。精排模型中，我们利用Bert构建一个句子对二分类模型，用来判断候选实体和问题中的mention相关度。具体流程如下：

1. 该模型的输入是一个句子对，text_a是标记了mention位置的文本，text_b是候选实体的描述文本。句子对经过Bert编码之后取[CLS]向量，再经过全连接层，得到上下文特征；
2. 合并粗排的三个特征进行全连接的融合训练；
3. 对候选实体进行二次排序；
4. 预测，选择Top 1的实体作为mention链接的实体；

同时对训练进行了一些优化，利用知识图谱中的关系三元组构建消歧的样本，关系三元组包括头实体、关系和尾实体。头实体和尾实体有多种表达方式（mention），利用这些不同的表达方式，我们可以去构建大量的正负样本，来帮助我们去学习mention和实体之间的语义特征关系，只需要少量经过标注的线上问题，就可以达到较好的消歧效果。

### 实体推荐

![image-20210615143942262](https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615143943.png)

这两张图展示了实体推荐的应用场景，实体推荐是根据给定的实体推荐一系列相关的实体。我们对实体推荐的工作暂时还处于起步的阶段，并没有考虑复杂的个性化推荐，目前只关注实体之间的相似度。

左图展示了实体链接如何应用于智能问答问题推荐，问题通过SLU处理之后会得到其意图和主实体，然后借助实体推荐得到相关的实体，相关实体被用来构建相关的问题，比如说”武汉大学周边好吃的？“，识别到其主实体为”武汉大学“、核心意图为”美食“，以此推荐实体相关的问题，比如说”华中科技大学周边有什么好吃的？“，”清华大学周边有什么好吃的？“，”武汉科技大学周边有什么好吃的？“。同时实现了推荐意图相关的问题，比如说”武汉大学周边有什么好玩的？“，”武汉大学周边有什么景点？“，”武汉大学周边有什么酒店？“等等。

右图展示了实体推荐在SS图谱自动化构建平台上的应用，当用户搜索一个实体的时候，平台会为其推荐相关的实体。

![image-20210615145107611](https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615145109.png)

实体推荐的难点在于”冷启动问题“，即如何去寻找实体的相关实体。

我们发现百科页面关系三元组以及新闻中的共享实体，都可以作为相关实体进行推荐。于是我们对百科页面知识图谱中的关系三元组和经过实体链接处理的新闻中的实体进行抽取，以类别为标准进行筛分，作为实体推荐模型的正样本。而负样本可以从库中的其他实体中抽取。

实体推荐模型分为两个部分，表示模型和匹配模型：

+ 表示模型  利用第二节中的DKRL模型进行知识表示学习。学习关系三元组中的结构化信息，编码部分使用Bert进行替换；

+ 匹配模型  利用DSSSM模型，复用了表示模型中学习到的参数，将两个实体编码成向量，通过计算余弦相似度来去衡量两个实体之间的相关度；

### 知识补全

![image-20210615150141802](https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615150143.png)


在构建知识图谱时，需要从半结构化或者非结构化数据中抽取三元组，但这些三元组难免会存在信息缺失情况，比如左图中，小米代表人物中林斌、王翔等人，都缺失了超链接，撒贝宁配偶、父母、妹妹倒也都缺失了超链接，这就导致在构建知识图谱时，不能获取完整的关系三元组。

实体补全任务可以概括为：针对已知的头实体、关系和尾实体mention的情况下，关联库中的实体以补全三元组。我们的设计方案如下：

1. 利用Schema去限定尾实体的类别；
2. 通过尾实体的mention筛选得到尾实体的候选实体，构造三元组；

3. 通过三元组分类模型判断构造的三元组是否正确；
4. 经过对这些三元组的分数进行排序之后，选择Top 1且预测正确的三元组；

![image-20210615151113966](https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615151115.png)

三元组的构建也考虑了描述实体的文本，我们再次利用了神通广大的BERT完成模型的构建，参考了KG-BERT这篇论文。

将已知的关系三元组如上图所示进行构造，text_a是头实体的描述文本，text_b是关系的文本名称，text_c是尾实体的描述文本，这些输入经过BERT的编码之后，再经过一个全连接层，计算得到语义特征，并和另外一个结构化的特征进行融合，最终得到一个评价分数。这里的”结构化特征“由蓝色框中的方程进行表示，整个模型的loss，可以用红色框中的方程表示。

举个例子，比如判断三元组{撒贝宁，配偶，李白}是否正确，”李白“的第一个候选实体是正确的，可以作为正样本，其他实体都是负样本，然后对模型进行训练，预测每一对自动构建的三元组的分数，按照从大到小的顺序进行排序，选择分数大于0.5且Top 1的三元组作为正确的三元组，补充到知识图谱当中。

## 总结与展望

![image-20210615152937867](https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615152939.png)

## 参考文献

![image-20210615152902876](https://my-picbed.oss-cn-hangzhou.aliyuncs.com/20210615152904.png)

## Q&A

Q：在实体链接的过程中，它的正负样本的比例是什么？

A：1:3~1:5。

Q：这个比例是如何确定的？

A：这是通常情况下会选取的比例。

Q：负样本的选取是随机的还是有其他策略？

A：采用动态负采样，然后将模型每一次学错的样本，放入到我们采样的副样本中，进行下一轮的迭代，让他去学习，用这种策略去加强模型对于预测错误样本的一些纠正。



Q：在知识补全过程中，评测指标是什么？

A：最重要是准确率，我们这边入库的标准就是要在95%以上，人工评测之后95%以上我们大概才会考虑入库。而召回率很难考量。

Q：知识补全举的例子是之前已经存在于知识库的，这个补全的信息是如何取得的？

A：训练的是已经存在知识图谱中的关系三元组，但是做预测的时候，我们仅仅只知道头实体关系以及尾实体的mention。



Q：实体链接和推理任务的区别在哪里？

A：实体链接是匹配库中的实体，这不算是一个推理过程，最多只能算一个匹配的过程。
